{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Machine Learning : Naive Bayes\n",
    "\n",
    "It is grounded in probability, which can be powerful. Sometimes it is called naive when we don't consider how classes relate to each other. For example, when we are wondering whether or not an email should be considered spam, we don't consider the fact that the class \"cash\" and the classes \"money\" are very correlated. For this reason, we end up doubling the probability that it is spam, which decreases accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this example: we want to find out how the words \"free\", \"pills\", and \"money\" relate to the likelihood that an email is spam. If we look at \"money\" only, we see that we really want to find `P(money|spam)` and `P(money|~spam)`.\n",
    "\n",
    "So how do we calculate these probabilities? Very simply, `P(money|spam) = Count(spam messages containing money) / Count(total spam messages)`. Easy enough, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So back to the naivety of the Naive Bayes classifier. When we assume independence, it looks a bit like this: `P(cash,money|spam) = P(cash|spam)P(money|spam)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what makes Naive Bayes Bayesian? It's because we are interested in making a prediction. We are interested in P(spam|x), not P(x|spam). So, we should apply Bayes rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us P(spam|x) = P(x|spam)P(spam)/P(x). Then, if P(spam|x) > P(~spam|x), then it is spam; switch these for ~spam. So basically we take the argmax of these two probabilities.\n",
    "\n",
    "Thus we basically want to find the Argmax over all given words of P(X|C)P(C) where C = spam or ~spam. P(C) is the prior. P(X|C) is the likelihood. P(C|X) is the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we model P(X|C)? We use vocabulary = words in doc U words not in doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our fit function, we want to calculate the mean and covariance for each class. This is all we need to represent the gaussian distribution. We also calculate the priors here P(C). \n",
    "\n",
    "In predict, loop through every sample we want to predict on, then loop through each class. We use the mean and variance to calculate the log pdf of a sample being in this class. Add that to the prior to get the posterior. If this is better than the max posterior we found so far, we set this to our best current prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So consider this example. Is it more likely that a document containing money, ~pills, ~free is spam or not spam?\n",
    "\n",
    "Well, recall that we want to calculate the probabilities...\n",
    "\n",
    "P(spam|money, ~free, ~pills) and also P(~spam|money, ~free, ~pills)\n",
    "\n",
    "So we can expand this into...\n",
    "\n",
    "P(spam|money, ~free, ~pills) = P(money, ~free, ~pills|spam)P(spam) = P(money|spam)P(~free|spam)P(~pills|spam)P(spam)\n",
    "P(~spam|money, ~free, ~pills) = P(money, ~free, ~pills|~spam)P(~spam) = P(money|~spam)P(~free|~spam)P(~free|spam)P(~spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why is multivariate covariance non-naive? Well, if 2 random variables are independent, then their covariance is 0. But if two variables are Gaussian distributed and their covariance is zero, then they are independent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
